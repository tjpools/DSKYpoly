{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56366340",
   "metadata": {},
   "source": [
    "# üî¨ DSKYpoly Data Science Showcase\n",
    "*From Polynomial Mathematics to Real-World Data Science*\n",
    "\n",
    "This notebook demonstrates how DSKYpoly's mathematical foundation can be leveraged for advanced data science applications.\n",
    "\n",
    "## üéØ What We'll Explore\n",
    "1. **Polynomial Regression Mastery** - Advanced curve fitting techniques\n",
    "2. **Financial Mathematics** - Stock price trend analysis\n",
    "3. **Signal Processing** - Noise reduction and pattern recognition\n",
    "4. **Scientific Computing** - High-precision mathematical modeling\n",
    "5. **Interactive Visualizations** - Professional data science presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b58ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the DSKYpoly data science toolkit\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom toolkit\n",
    "from polynomial_toolkit import PolynomialAnalyzer, FinancialPolynomialAnalyzer\n",
    "\n",
    "print(\"üöÄ DSKYpoly Data Science Environment Loaded!\")\n",
    "print(f\"üìä NumPy version: {np.__version__}\")\n",
    "print(f\"üêº Pandas version: {pd.__version__}\")\n",
    "print(f\"üìà Plotly available for interactive visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08e9c40",
   "metadata": {},
   "source": [
    "## üî¨ Demo 1: Advanced Polynomial Regression\n",
    "\n",
    "Let's start with a complex dataset that showcases the power of polynomial modeling with automatic degree selection and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3711a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a complex synthetic dataset\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "X = np.linspace(0, 4*np.pi, n_samples)\n",
    "\n",
    "# Complex function with multiple components\n",
    "true_function = (2*np.sin(X) + 0.5*X**2 - 0.1*X**3 + \n",
    "                np.cos(2*X) + 0.3*X)\n",
    "noise = np.random.normal(0, 0.5, n_samples)\n",
    "y = true_function + noise\n",
    "\n",
    "# Split into train/test\n",
    "split_idx = int(0.8 * n_samples)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"üìä Dataset created: {len(X_train)} training, {len(X_test)} test samples\")\n",
    "print(f\"üéØ Function: 2*sin(x) + 0.5*x¬≤ - 0.1*x¬≥ + cos(2x) + 0.3*x + noise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and analyze with different regularization techniques\n",
    "analyzers = {\n",
    "    'Standard': PolynomialAnalyzer(max_degree=15),\n",
    "    'Ridge': PolynomialAnalyzer(max_degree=15, regularization='ridge', alpha=1.0),\n",
    "    'Lasso': PolynomialAnalyzer(max_degree=15, regularization='lasso', alpha=0.1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, analyzer in analyzers.items():\n",
    "    print(f\"\\nüîç Analyzing with {name} regularization...\")\n",
    "    \n",
    "    # Find optimal degree and fit model\n",
    "    cv_results = analyzer.find_optimal_degree(X_train, y_train)\n",
    "    analyzer.fit_best_model(X_train, y_train)\n",
    "    \n",
    "    # Generate performance report\n",
    "    report = analyzer.generate_performance_report(X_train, y_train, X_test, y_test)\n",
    "    results[name] = report\n",
    "    \n",
    "    print(f\"  Best degree: {report['best_degree']}\")\n",
    "    print(f\"  Test R¬≤: {report['test_r2']:.4f}\")\n",
    "    print(f\"  Generalization gap: {report['generalization_gap']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a5f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Model Fits Comparison', 'Performance Metrics',\n",
    "                   'Cross-Validation Curves', 'Prediction Confidence'),\n",
    "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    ")\n",
    "\n",
    "# Plot 1: Model fits comparison\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X_train, y=y_train, mode='markers', name='Training Data',\n",
    "              marker=dict(color='lightblue', size=4, opacity=0.6)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X_test, y=y_test, mode='markers', name='Test Data',\n",
    "              marker=dict(color='lightcoral', size=4, opacity=0.6)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X, y=true_function, mode='lines', name='True Function',\n",
    "              line=dict(color='black', width=2, dash='dash')),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "colors = ['red', 'green', 'purple']\n",
    "for i, (name, analyzer) in enumerate(analyzers.items()):\n",
    "    y_pred = analyzer.best_model.predict(X.reshape(-1, 1))\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=X, y=y_pred, mode='lines', name=f'{name} Fit',\n",
    "                  line=dict(color=colors[i], width=2)),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot 2: Performance metrics\n",
    "metrics = ['test_r2', 'generalization_gap']\n",
    "metric_names = ['Test R¬≤', 'Generalization Gap']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[name][metric] for name in results.keys()]\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=list(results.keys()), y=values, name=metric_names[i],\n",
    "              marker=dict(color=colors[i])),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot 3: Cross-validation curves for Ridge regularization\n",
    "ridge_analyzer = analyzers['Ridge']\n",
    "degrees = list(ridge_analyzer.cv_scores.keys())\n",
    "cv_means = [ridge_analyzer.cv_scores[d]['mean'] for d in degrees]\n",
    "cv_stds = [ridge_analyzer.cv_scores[d]['std'] for d in degrees]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=degrees, y=cv_means,\n",
    "              error_y=dict(type='data', array=cv_stds),\n",
    "              mode='lines+markers', name='Ridge CV Score',\n",
    "              line=dict(color='green')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Prediction confidence for best model\n",
    "best_analyzer = min(analyzers.values(), key=lambda a: results[list(analyzers.keys())[list(analyzers.values()).index(a)]]['test_mse'])\n",
    "X_future = np.linspace(X.max(), X.max() + 2, 50)\n",
    "pred_results = best_analyzer.predict_with_confidence(X_future)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=X_future, y=pred_results['predictions'],\n",
    "              mode='lines', name='Future Prediction',\n",
    "              line=dict(color='blue')),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=np.concatenate([X_future, X_future[::-1]]),\n",
    "        y=np.concatenate([pred_results['upper_bound'], \n",
    "                         pred_results['lower_bound'][::-1]]),\n",
    "        fill='toself', fillcolor='rgba(0,0,255,0.2)',\n",
    "        line=dict(color='rgba(255,255,255,0)'),\n",
    "        name='Confidence Interval'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üî¨ DSKYpoly Advanced Polynomial Analysis',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b2826",
   "metadata": {},
   "source": [
    "## üìà Demo 2: Financial Time Series Analysis\n",
    "\n",
    "Now let's apply our polynomial techniques to financial data analysis, demonstrating real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0596b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic stock price data\n",
    "np.random.seed(123)\n",
    "n_days = 500\n",
    "dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')\n",
    "\n",
    "# Simulate stock price with multiple components\n",
    "time_idx = np.arange(n_days)\n",
    "\n",
    "# Long-term trend (polynomial)\n",
    "trend = 100 + 0.1*time_idx + 0.0001*time_idx**2 - 0.0000001*time_idx**3\n",
    "\n",
    "# Seasonal pattern\n",
    "seasonal = 5 * np.sin(2*np.pi*time_idx/252) + 2 * np.cos(2*np.pi*time_idx/126)\n",
    "\n",
    "# Random walk component\n",
    "random_walk = np.cumsum(np.random.normal(0, 0.5, n_days))\n",
    "\n",
    "# Market shocks (occasional large moves)\n",
    "shocks = np.zeros(n_days)\n",
    "shock_days = np.random.choice(n_days, size=10, replace=False)\n",
    "shocks[shock_days] = np.random.normal(0, 10, 10)\n",
    "shock_component = np.cumsum(shocks)\n",
    "\n",
    "# Combine all components\n",
    "prices = trend + seasonal + random_walk + shock_component\n",
    "prices = np.maximum(prices, 50)  # Ensure positive prices\n",
    "\n",
    "print(f\"üìä Generated {n_days} days of synthetic stock data\")\n",
    "print(f\"üí∞ Price range: ${prices.min():.2f} - ${prices.max():.2f}\")\n",
    "print(f\"üìà Total return: {((prices[-1]/prices[0]) - 1)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3085fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive financial analysis\n",
    "fin_analyzer = FinancialPolynomialAnalyzer(max_degree=8, regularization='ridge', alpha=0.5)\n",
    "\n",
    "# Analyze the full time series\n",
    "trend_analysis = fin_analyzer.analyze_price_trend(prices, dates)\n",
    "\n",
    "print(\"üîç Financial Analysis Results:\")\n",
    "print(f\"  Trend Direction: {trend_analysis['trend_direction']}\")\n",
    "print(f\"  Total Return: {trend_analysis['total_return']*100:.2f}%\")\n",
    "print(f\"  Annualized Volatility: {trend_analysis['annualized_volatility']*100:.2f}%\")\n",
    "print(f\"  Sharpe Ratio: {trend_analysis['sharpe_ratio']:.3f}\")\n",
    "print(f\"  Optimal Polynomial Degree: {trend_analysis['best_degree']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a8a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive financial visualization\n",
    "fig = fin_analyzer.plot_financial_analysis(prices, dates, 'DEMO_STOCK')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459edcc5",
   "metadata": {},
   "source": [
    "## üåä Demo 3: Signal Processing Applications\n",
    "\n",
    "Demonstrate how polynomial methods can be used for signal denoising and pattern recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863f2501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a noisy signal\n",
    "np.random.seed(456)\n",
    "t = np.linspace(0, 10, 1000)\n",
    "\n",
    "# Original signal (combination of sinusoids)\n",
    "clean_signal = (2*np.sin(2*np.pi*t) + \n",
    "               0.5*np.sin(6*np.pi*t) + \n",
    "               np.cos(4*np.pi*t) +\n",
    "               0.3*t)  # Linear trend\n",
    "\n",
    "# Add various types of noise\n",
    "gaussian_noise = np.random.normal(0, 0.5, len(t))\n",
    "impulse_noise = np.zeros_like(t)\n",
    "impulse_indices = np.random.choice(len(t), size=20, replace=False)\n",
    "impulse_noise[impulse_indices] = np.random.uniform(-3, 3, 20)\n",
    "\n",
    "noisy_signal = clean_signal + gaussian_noise + impulse_noise\n",
    "\n",
    "print(f\"üåä Generated signal with {len(t)} samples\")\n",
    "print(f\"üìä SNR: {10*np.log10(np.var(clean_signal)/np.var(gaussian_noise)):.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d3c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply polynomial smoothing with different window sizes\n",
    "def polynomial_smooth(signal, window_size, degree=3):\n",
    "    \"\"\"Apply polynomial smoothing to a signal.\"\"\"\n",
    "    smoothed = np.zeros_like(signal)\n",
    "    half_window = window_size // 2\n",
    "    \n",
    "    for i in range(len(signal)):\n",
    "        start = max(0, i - half_window)\n",
    "        end = min(len(signal), i + half_window + 1)\n",
    "        \n",
    "        if end - start > degree + 1:  # Ensure enough points for fitting\n",
    "            x_window = np.arange(start, end) - i\n",
    "            y_window = signal[start:end]\n",
    "            \n",
    "            # Fit polynomial\n",
    "            coeffs = np.polyfit(x_window, y_window, degree)\n",
    "            smoothed[i] = np.polyval(coeffs, 0)  # Evaluate at center point\n",
    "        else:\n",
    "            smoothed[i] = signal[i]  # Keep original value if not enough points\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "# Apply different smoothing strategies\n",
    "window_sizes = [21, 51, 101]\n",
    "smoothed_signals = {}\n",
    "\n",
    "for ws in window_sizes:\n",
    "    smoothed = polynomial_smooth(noisy_signal, ws, degree=3)\n",
    "    smoothed_signals[f'Window_{ws}'] = smoothed\n",
    "    \n",
    "    # Calculate denoising performance\n",
    "    mse = np.mean((clean_signal - smoothed)**2)\n",
    "    print(f\"Window size {ws}: MSE = {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create signal processing visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Original vs Noisy Signal', 'Polynomial Denoising Results',\n",
    "                   'Frequency Domain Analysis', 'Performance Comparison'),\n",
    ")\n",
    "\n",
    "# Plot 1: Original vs noisy\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=clean_signal, mode='lines', name='Clean Signal',\n",
    "              line=dict(color='blue', width=2)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=noisy_signal, mode='lines', name='Noisy Signal',\n",
    "              line=dict(color='red', width=1, opacity=0.7)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Plot 2: Denoising results\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=t, y=clean_signal, mode='lines', name='True Signal',\n",
    "              line=dict(color='black', width=2, dash='dash')),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "colors = ['green', 'orange', 'purple']\n",
    "for i, (name, smoothed) in enumerate(smoothed_signals.items()):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=t, y=smoothed, mode='lines', name=f'Smoothed {name}',\n",
    "                  line=dict(color=colors[i], width=2)),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot 3: Frequency domain (simplified)\n",
    "from scipy.fft import fft, fftfreq\n",
    "freqs = fftfreq(len(t), t[1] - t[0])[:len(t)//2]\n",
    "clean_fft = np.abs(fft(clean_signal))[:len(t)//2]\n",
    "noisy_fft = np.abs(fft(noisy_signal))[:len(t)//2]\n",
    "best_smoothed_fft = np.abs(fft(smoothed_signals['Window_51']))[:len(t)//2]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=freqs, y=clean_fft, mode='lines', name='Clean FFT',\n",
    "              line=dict(color='blue')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=freqs, y=noisy_fft, mode='lines', name='Noisy FFT',\n",
    "              line=dict(color='red', opacity=0.7)),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=freqs, y=best_smoothed_fft, mode='lines', name='Smoothed FFT',\n",
    "              line=dict(color='green')),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Plot 4: Performance comparison\n",
    "mse_values = []\n",
    "window_labels = []\n",
    "for name, smoothed in smoothed_signals.items():\n",
    "    mse = np.mean((clean_signal - smoothed)**2)\n",
    "    mse_values.append(mse)\n",
    "    window_labels.append(name.replace('Window_', 'W'))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=window_labels, y=mse_values, name='MSE',\n",
    "          marker=dict(color='purple')),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üåä Signal Processing with Polynomial Methods',\n",
    "    height=800,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Time\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Frequency\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Window Size\", row=2, col=2)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83512982",
   "metadata": {},
   "source": [
    "## üéØ Summary & Next Steps\n",
    "\n",
    "### üèÜ What We've Demonstrated\n",
    "\n",
    "1. **Advanced Polynomial Regression**\n",
    "   - Automatic degree selection with cross-validation\n",
    "   - Regularization techniques (Ridge/Lasso) for overfitting prevention\n",
    "   - Performance evaluation and generalization analysis\n",
    "\n",
    "2. **Financial Time Series Analysis**\n",
    "   - Trend detection and modeling\n",
    "   - Risk metrics calculation (volatility, Sharpe ratio)\n",
    "   - Future price prediction with confidence intervals\n",
    "\n",
    "3. **Signal Processing Applications**\n",
    "   - Noise reduction using polynomial smoothing\n",
    "   - Frequency domain analysis\n",
    "   - Performance optimization\n",
    "\n",
    "### üöÄ Expansion Opportunities\n",
    "\n",
    "1. **Machine Learning Integration**\n",
    "   - Feature engineering with polynomial features\n",
    "   - Ensemble methods combining polynomial and ML models\n",
    "   - Deep learning with polynomial activation functions\n",
    "\n",
    "2. **Real-World Applications**\n",
    "   - Climate data analysis and forecasting\n",
    "   - Biomedical signal processing (ECG, EEG)\n",
    "   - Economic modeling and policy analysis\n",
    "\n",
    "3. **Performance Optimization**\n",
    "   - GPU acceleration with CuPy/JAX\n",
    "   - Parallel processing with Dask\n",
    "   - Integration with assembly-optimized DSKYpoly core\n",
    "\n",
    "### üìà Data Science Impact\n",
    "\n",
    "DSKYpoly's mathematical foundation provides unique advantages:\n",
    "- **Theoretical Rigor**: Deep understanding of polynomial mathematics\n",
    "- **Computational Excellence**: Assembly-optimized performance\n",
    "- **Cross-Platform Power**: Windows Anaconda + Linux optimization\n",
    "- **Educational Value**: Bridge between pure math and applications\n",
    "\n",
    "*\"From solving polynomials to solving real-world problems through data science\"* üéØ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c058d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration: Create a summary dashboard\n",
    "print(\"üéâ DSKYpoly Data Science Showcase Complete!\")\n",
    "print(\"\\nüìä Capabilities Demonstrated:\")\n",
    "print(\"  ‚úÖ Advanced polynomial regression with regularization\")\n",
    "print(\"  ‚úÖ Financial time series analysis and risk modeling\")\n",
    "print(\"  ‚úÖ Signal processing and noise reduction\")\n",
    "print(\"  ‚úÖ Interactive visualizations and professional reporting\")\n",
    "print(\"  ‚úÖ Cross-validation and performance optimization\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for expansion into:\")\n",
    "print(\"  üî¨ Scientific computing and research\")\n",
    "print(\"  üí∞ Quantitative finance and trading\")\n",
    "print(\"  üè• Biomedical data analysis\")\n",
    "print(\"  üåç Climate and environmental modeling\")\n",
    "print(\"  ü§ñ Machine learning and AI applications\")\n",
    "\n",
    "print(\"\\nüéØ The mathematical foundation of DSKYpoly now powers\")\n",
    "print(\"   a comprehensive data science platform!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
